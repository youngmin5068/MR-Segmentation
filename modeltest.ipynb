{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from topTcbam_UNet import top_t_cbam_UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from metric import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch as torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from einops import rearrange\n",
    "from custom_transforms import *\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from monai.transforms import AsDiscrete\n",
    "\n",
    "\n",
    "class tumor_Dataset_testing(Dataset):\n",
    "    def __init__(self,path,patient, train=True):\n",
    "        self.patientID = patient\n",
    "        self.path = path\n",
    "        self.train = train\n",
    "        self.train_path_list = []\n",
    "        self.train_list = []\n",
    "\n",
    "\n",
    "        self.label_path_list = []\n",
    "        self.label_list = []\n",
    "\n",
    "        self.train_path = path + \"/input\"\n",
    "        self.label_path = path + \"/target\"\n",
    "\n",
    "        \n",
    "        for file in os.listdir(self.train_path):\n",
    "            if file.split(\"_\")[0] == str(self.patientID):\n",
    "                self.train_path_list.append(os.path.join(self.train_path,file))\n",
    "        self.train_path_list.sort()\n",
    "                \n",
    "        for file in os.listdir(self.label_path):\n",
    "            if file.split(\"_\")[0] == str(self.patientID):\n",
    "                self.label_path_list.append(os.path.join(self.label_path,file))\n",
    "        self.label_path_list.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_path_list)\n",
    "\n",
    "    def preprocessing(self,train_path, label_path):\n",
    "\n",
    "        input_slice = pydicom.read_file(train_path)\n",
    "        input_img = input_slice.pixel_array\n",
    "        input_img = apply_voi_lut(input_img, input_slice)\n",
    "        epsilon = 1e-10\n",
    "        min_val = np.min(input_img)\n",
    "        max_val = np.max(input_img)\n",
    "        input_img = (input_img - min_val) / (max_val - min_val+epsilon)\n",
    "        input_img = Image.fromarray(input_img)\n",
    "\n",
    "        target_slice = pydicom.read_file(label_path)\n",
    "        target_img = target_slice.pixel_array\n",
    "        epsilon = 1e-10\n",
    "        min_val = np.min(target_img)\n",
    "        max_val = np.max(target_img)\n",
    "        target_img = (target_img - min_val) / (max_val - min_val+epsilon)\n",
    "\n",
    "        target_img = Image.fromarray(target_img)\n",
    "\n",
    "        return input_img, target_img\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        if self.train:\n",
    "            self.transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                transforms.Resize((512,512)),\n",
    "                                                customRandomRotate(degrees=180,SEED=idx),\n",
    "                                                customRandomHorizontalFlip(p=0.5,SEED=idx),\n",
    "                                                #customRandomResizedCrop(SEED=idx,size=(256,256))\n",
    "                                                ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                 transforms.Resize((512,512))\n",
    "                                                 ])\n",
    "\n",
    "        \n",
    "\n",
    "        image,label = self.preprocessing(self.train_path_list[idx], self.label_path_list[idx])    \n",
    "\n",
    "        input_image = self.transform((image))\n",
    "        target_image = self.transform((label))\n",
    "\n",
    "        threshold = AsDiscrete(threshold=0.5)\n",
    "        target_image = threshold(target_image)\n",
    "\n",
    "\n",
    "        return input_image, target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_path = '/workspace/IITP/task_2D/dir_checkpoint_tumorResult/top_t_cbam_002_UNet_dataedited.pth'\n",
    "net = top_t_cbam_UNet(1,1,percent_t=0.02).to(device=\"cuda:0\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net = nn.DataParallel(net,device_ids=[0,1,2,3]) \n",
    "net.load_state_dict(torch.load(net_path))\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seed(7777777)\n",
    "\n",
    "dataset = tumor_Dataset(\"/mount_folder/Tumors/test/undersampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "test_excel = pd.read_excel(\"/mount_folder/test_data.xlsx\")\n",
    "test_list = test_excel[\"Patient\"].tolist()\n",
    "\n",
    "\n",
    "def evaluate_segmentation(model, dataset, test_list, device='cuda:0'):\n",
    "    # 초기 confusion matrix 요소 값\n",
    "    TP_total = 0\n",
    "    FP_total = 0\n",
    "    FN_total = 0\n",
    "    TN_total = 0\n",
    "    \n",
    "    model.eval()\n",
    "    test_loader = DataLoader(dataset=dataset,batch_size=1,shuffle=False)\n",
    "\n",
    "    for input_image, true_mask in test_loader:\n",
    "        input_image = input_image.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predicted_mask = model(input_image)\n",
    "\n",
    "        predicted_mask = predicted_mask.cpu().numpy()\n",
    "        true_mask = true_mask.cpu().numpy()\n",
    "\n",
    "        # 이진 분류를 위한 threshold 적용\n",
    "        predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # 현재 slice에 대한 confusion matrix 요소 계산\n",
    "        TP = np.sum((predicted_mask == 1) & (true_mask == 1))\n",
    "        FP = np.sum((predicted_mask == 1) & (true_mask == 0))\n",
    "        FN = np.sum((predicted_mask == 0) & (true_mask == 1))\n",
    "        TN = np.sum((predicted_mask == 0) & (true_mask == 0))\n",
    "        \n",
    "        # 현재 slice의 결과를 전체 결과에 합산\n",
    "        TP_total += TP\n",
    "        FP_total += FP\n",
    "        FN_total += FN\n",
    "        TN_total += TN\n",
    "    \n",
    "    # 모든 slices를 기반으로 한 Dice Score 계산\n",
    "    dice = (2 * TP_total) / (2 * TP_total + FP_total + FN_total)\n",
    "    \n",
    "    return dice\n",
    "\n",
    "# 사용 예시\n",
    "# patient_slices = load_slices(patient_number=\"12345\")  # patient_slices는 (input_image, true_mask) 튜플의 리스트\n",
    "# dice_score = evaluate_segmentation(model, patient_slices)\n",
    "# print(dice_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167753 : 0.8580580363202042\n",
      "1199340 : 0.3412361244346992\n",
      "1199440 : 0.6140790287886377\n",
      "1199470 : 0.33448601068846273\n",
      "1199870 : 0.02827521206409048\n",
      "1199940 : 0.624931438544004\n",
      "1219657 : 0.75208734746307\n",
      "1229070 : 0.5512407652964577\n",
      "1249647 : 0.8179940083376043\n",
      "1284590 : 0.8392113063275914\n",
      "1299050 : 0.8269854508386618\n",
      "1299690 : 0.9107241876455584\n",
      "1329450 : 0.8734185427885551\n",
      "1329490 : 0.6980462589801998\n",
      "1364554 : 0.0\n",
      "1389134 : 0.38798977853492334\n",
      "1399050 : 0.7254370844619552\n",
      "1399230 : 0.8343834383438344\n",
      "1399820 : 0.6897493174484984\n",
      "1399990 : 0.7516377397885945\n",
      "1430946 : 0.4187323240725337\n",
      "1449557 : 0.8381968359182828\n",
      "1499030 : 0.0\n",
      "1499100 : 0.7543140028288543\n",
      "1499560 : 0.8267552970502701\n",
      "1587857 : 0.7281387858940702\n",
      "2099330 : 0.8648466949986794\n",
      "2296328 : 0.8717900087243485\n",
      "2319117 : 0.0\n",
      "2399130 : 0.3109699486928903\n",
      "2559967 : 0.6833134159381093\n",
      "2697891 : 0.9164044943820224\n",
      "2709627 : 0.8801586518184836\n",
      "2899910 : 0.911361804995971\n",
      "3134327 : 0.8833291213882571\n",
      "3341384 : 0.8558036615359313\n",
      "3399330 : 0.8067326397699399\n",
      "3479830 : 0.11125448028673836\n",
      "3519727 : 0.7826735651546144\n",
      "3529930 : 0.9353258206761391\n",
      "4161398 : 0.7015043547110056\n",
      "4267668 : 0.822052850166583\n",
      "4349147 : 0.7429368811408036\n",
      "4399780 : 0.0\n",
      "4401828 : 0.7639705882352941\n",
      "4429360 : 0.44315244582729874\n",
      "4429480 : 0.5615337043908473\n",
      "4449177 : 0.8547819019235979\n",
      "4459037 : 0.8597826086956522\n",
      "4459057 : 0.7821152973218338\n",
      "4539570 : 0.1860019175455417\n",
      "4549187 : 0.8129492043099373\n",
      "4589697 : 0.8627503696733432\n",
      "4629787 : 0.9254387881436167\n",
      "4699030 : 0.9049985384390529\n",
      "4699900 : 0.49567411679884643\n",
      "4789887 : 0.29957520162531553\n"
     ]
    }
   ],
   "source": [
    "dice_dict = {}\n",
    "for patient in test_list:\n",
    "    dataset = tumor_Dataset_testing(path=\"/mount_folder/Tumors/test\",patient=patient, train=False)\n",
    "    model = net\n",
    "    dice = evaluate_segmentation(model, dataset, test_list, device='cuda:0')\n",
    "    print(f\"{patient} : {dice}\")\n",
    "    dice_dict[f\"{patient}\"] = dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
